---
title: 01-java并发编程基础
description: 
published: true
date: 2023-09-08T09:06:02.197Z
tags: 咕泡, 并发, 面试
editor: markdown
dateCreated: 2023-06-20T08:09:20.098Z
---

# 01 谈谈你对AQS的理解  TODO
1. AQS 是多线程同步器，它是 J.U.C 包中多个组件的底层实现，如 Lock、
CountDownLatch、Semaphore 等都用到了 AQS.
2. 从本质上来说，AQS 提供了两种锁机制，分别是排它锁，和 共享锁。
 - 排它锁，就是存在多线程竞争同一共享资源时，同一时刻只允许一个线程访问该共享资源，也就是多个线程中只能有一个线程获得锁资源，比如 Lock 中的ReentrantLock 重入锁实现就是用到了 AQS 中的排它锁功能。
 - 共享锁也称为读锁，就是在同一时刻允许多个线程同时获得锁资源，比如
CountDownLatch 和 Semaphore 都是用到了 AQS 中的共享锁功能。

# 02 lock 和 synchronized 区别
1. 从功能角度来看，Lock 和 Synchronized 都是 Java 中用来解决线程安全问题的工具。
2. 从特性来看，
	- a. Synchronized 是 Java 中的同步关键字，Lock 是 J.U.C 包中提供的接口，这个接口有很多实现类，其中就包括 ReentrantLock 重入锁。
  - b. Synchronized 可以通过两种方式来控制锁的粒度。一种是把 synchronized 关键字修饰在方法层面，另一种是修饰在代码块上，并且我们可以通过 Synchronized 加锁对象的声明周期来控。
   - 制锁的作用范围，比如锁对象是静态对象或者类对象，那么这个锁就是全局锁。
   - 如果锁对象是普通实例对象，那这个锁的范围取决于这个实例的声明周期。
   - Lock 锁的粒度是通过它里面提供的 lock()和 unlock()方法决定的（贴图），包裹在这两个方法之间的代码能够保证线程安全性。而锁的作用域取决于 Lock 实例的生命周期。
  - c. Lock 比 Synchronized 的灵活性更高，Lock 可以自主决定什么时候加锁，什么时候释放锁，只需要调用 lock()和 unlock()这两个方法就行，同时 Lock 还提供了非阻塞的竞争锁方法 tryLock()方法，这个方法通过返回 true/false 来告诉当前线程是否已经有其他线程正在使用锁。 Synchronized 由于是关键字，所以它无法实现非阻塞竞争锁的方法，另外，Synchronized 锁的释放是被动的，就是当 Synchronized 同步代码块执行完以后或者代码出现异常时才会释放    
  - d.  Lock 提供了公平锁和非公平锁的机制，公平锁是指线程竞争锁资源时，如果已经有其他线程正在排队等待锁释放，那么当前竞争锁资源的线程无法插队。而非公平锁，就是不管是否有线程在排队等待锁，它都会尝试去竞争一次锁。Synchronized 只提供了一种非公平锁的实现.(公平锁老实在队列里呆着，非公平锁会先竞争一次锁，再进入队列)，
3.   从性能方面来看，Synchronized 和 Lock 在性能方面相差不大，在实现上会有一些区别，Synchronized 引入了偏向锁、轻量级锁、重量级锁以及锁升级的方式来优化加锁的性能，而 Lock 中则用到了自旋锁的方式来实现性能优化。
  
# 03 线程池如何知道一个线程的任务已经执行完成 
1. 在线程池内部，当我们把一个任务丢给线程池去执行，线程池会调度工作线程来执行这个任务的 run 方法，run 方法正常结束，也就意味着任务完成了。所以线程池中的工作线程是通过同步调用任务的 run()方法并且等待 run 方法返回后，再去统计任务的完成数量。
2. 如果想在线程池外部去获得线程池内部任务的执行状态，有几种方法可以实现。
  - a. 线程池提供了一个 isTerminated()方法，可以判断线程池的运行状态，我们可以循环判断 isTerminated()方法的返回结果来了解线程池的运行状态，一旦线程池的运行状态是 Terminated，意味着线程池中的所有任务都已经执行完了。想要通过这个方法获取状态的前提是，程序中主动调用了线程池的 shutdown()方法。在实际业务中，一般不会主动去关闭线程池，因此这个方法在实用性和灵活性方面都不是很好
  - b.  在线程池中，有一个 submit()方法，它提供了一个 Future 的返回值，我们通过 Future.get()方法来获得任务的执行结果，当线程池中的任务没执行完之前，future.get()方法会一直阻塞，直到任务执行结束。因此，只要 future.get()方法正常返回，也就意味着传入到线程池中的任务已经执行完成了！(execute方法返回是void )
  - c. 可以引入一个 CountDownLatch 计数器，它可以通过初始化指定一个计数器进行倒计时，其中有两个方法分别是 await()阻塞线程，以及 countDown()进行倒计时，一旦倒计时归零，所以被阻塞在 await()方法的线程都会被释放。基于这样的原理，我们可以定义一个 CountDownLatch 对象并且计数器为 1，接着在线程池代码块后面调用 await()方法阻塞主线程，然后，当传入到线程池中的任务执行完成后，调用 countDown()方法表示任务执行结束。最后，计数器归零 0，唤醒阻塞在 await()方法的线程。
  
# 04 什么叫做阻塞队列的有界和无界  
1. 阻塞队列，是一种特殊的队列，它在普通队列的基础上提供了两个附加功能
  - a. 当队列为空的时候，获取队列中元素的消费者线程会被阻塞，同时唤醒生产者线程。
  - b. 当队列满了的时候，向队列中添加元素的生产者线程被阻塞，同时唤醒消费者线程。
2. 其中，阻塞队列中能够容纳的元素个数，通常情况下是有界的，比如我们实例化一个 ArrayBlockingList，可以在构造方法中传入一个整形的数字，表示这个基于数组的阻塞队列中能够容纳的元素个数。这种就是有界队列。  
3. 而无界队列，就是没有设置固定大小的队列，不过它并不是像我们理解的那种元素没有任何限制，而是它的元素存储量很大，像 LinkedBlockingQueue，它的默认队列长度是 Integer.Max_Value，所以我们感知不到它的长度限制。
4. 无界队列存在比较大的潜在风险，如果在并发量较大的情况下，线程池中可以几乎无限制的添加任务，容易导致内存溢出的问题！

# 05 ConcurrentHashMap 底层具体实现？实现原理是什么
1. **整体结构**： ConcurrentHashMap 在 JDK1.8 中的存储结构，它由数组、单向链表、红黑树组成。  
  - 默认初始化一个长度为16的数组
  - 核心是hash表，依然存在hash冲突，ConcurrentHashMap采用链式寻址法来解决 hash 冲突。
  - 当 hash 冲突比较多的时候，会造成链表长度较长，这种情况会使得ConcurrentHashMap 中数据元素的查询复杂度变成 O(n)。因此在 JDK1.8 中，引入了红黑树的机制。
  - 当数组长度大于 64 并且链表长度大于等于 8 的时候，单项链表就会转换为红黑树。
  - 随着 ConcurrentHashMap 的动态扩容，一旦链表长度小于 8，红黑树会退化成单向链表。
2. **基本功能**：
 - 本质上是一个 HashMap，因此功能和 HashMap 一样，但是ConcurrentHashMap 在 HashMap 的基础上，提供了并发安全的实现。
 - 并发安全的主要实现是通过对指定的 Node 节点加锁，来保证数据更新的安全性。
 - ConcurrentHashMap 在性能方面做的优化：
 > 如何在并发性能和数据安全性之间做好平衡，在很多地方都有类似的设计，比如 cpu的三级缓存、mysql 的 buffer_pool、Synchronized 的锁升级等等。
 
  - 1. 在 JDK1.8 中，ConcurrentHashMap 锁的粒度是数组中的某一个节点，而在JDK1.7，锁定的是 Segment，锁的范围要更大，因此性能上会更低。
  - 2. 引入红黑树，降低了数据查询的时间复杂度，红黑树的时间复杂度是 O(logn)
  - 3. 当数组长度不够时，ConcurrentHashMap 需要对数组进行扩
容，在扩容的实现上，ConcurrentHashMap 引入了多线程并发扩容的机制，简单来说就是多个线程对原始数组进行分片后，每个线程负责一个分片的数据迁移，从而提升了扩容过程中数据迁移的效率。
  - 4. ConcurrentHashMap 中有一个 size()方法来获取总的元素个数，而在多线程并发场景中，在保证原子性的前提下来实现元素个数的累加，性能是非常低的。ConcurrentHashMap 在这个方面的优化主要体现在两个点： 
    a.  当线程竞争不激烈时，直接采用 CAS 来实现元素个数的原子递增。
    b. 如果线程竞争激烈，使用一个数组来维护元素个数，如果要增加总的元素个数，则直接从数组中随机选择一个，再通过 CAS 实现原子递增。它的核心思想是引入了数组来实现对并发更新的负载。
    
# 06 CAS机制
- CAS 是 Java 中 Unsafe 类里面的方法，它的全称是 CompareAndSwap，比较并交换的意思。它的主要功能是能够保证在多线程环境下，对于共享变量的修改的原子性。
- CompareAndSwap 的底层实现中，在多核 CPU 环境下，会增加一个 Lock指令对缓存或者总线加锁，从而保证比较并替换这两个指令的原子性。
- CAS 主要用在并发场景中，比较典型的使用场景有两个。
  1. J.U.C 里面 Atomic 的原子实现，比如 AtomicInteger，AtomicLong。
  2. 实现多线程对共享资源竞争的互斥性质，比如在 AQS、ConcurrentHashMap、ConcurrentLinkedQueue 等都有用到。
  
# 07 死锁的发生原因和怎么避免
- 原因：多线程下对共享资源竞争造成相互等待的现象。
 - 1. 互斥条件
 - 2. 不可剥夺条件
 - 3. 请求和保持条件： 不释放资源
 - 4. 循环等待条件
- 死锁后，只能通过人工干预来解决，比如重启，或kill进程。
- 对于请求和保持：一次性申请全部的资源
- 不可剥夺：申请资源失败，可主动释放它占有的资源
- 循环等待：按序申请资源，先申请小的，再申请大的。

# 08 volatile关键字的作用和实现原理
- 作用：
	1. 保证多线程下共享变量的可见性
  2. 增加内存屏障防止多个智力之间的重排序

- 可见性：一个线程修改共享变量后，其他线程立刻可以看到修改后的只。
- **造成可见性问题的原因**：
 1. **CPU 层面的高速缓存**：对于增加了 volatile 关键字修饰的共享变量，JVM 虚拟机会自动增加一个#Lock汇编指令，这个指令会根据 CPU 型号自动添加总线锁或/缓存锁
   - 1.1  总线锁： 锁定了 CPU 的前端总线，从而导致在同一时刻只能有一个线程去和内存通信，这样就避免了多线程并发造成的可见性。
   - 1.2  缓存锁是对总线锁的优化，因为总线锁导致了 CPU 的使用效率大幅度下降，所以缓存锁只针对 CPU 三级缓存中的目标数据加锁，缓存锁是使用 MESI 缓存一致性来实现的
 2. **指令重排序**：  所谓重排序，就是指令的编写顺序和执行顺序不一致，在多线程环境下导致可见性问题。指令重排序本质上是一种性能优化的手段，它来自于几个方面：
  - 2.1 CPU 层面，针对 MESI 协议的更进一步优化去提升 CPU 的利用率，引入了StoreBuffer 机制，而这一种优化机制会导致 CPU 的乱序执行。当然为了避免这样的问题，CPU 提供了**内存屏障指令**，上层应用可以在合适的地方插入内存屏障来避免 CPU 指令重排序问题。
  - 2.2 编译器的优化，编译器在编译的过程中，在不改变单线程语义和程序正确性的前提下，对指令进行合理的重排序优化来提升性能。 所以，如果对共享变量增加了 volatile 关键字，那么在编译器层面，就不会去触发编译器优化，同时再 JVM 里面，会插入内存屏障指令来避免重排序问题。
  
- 除了 volatile 以外，从 JDK5 开始，JMM 就使用了一种 Happens-Before 模型去描述多线程之间的内存可见性问题。如果两个操作之间具备 Happens-Before 关系，那么意味着这两个操作具备可见性关系，不需要再额外去考虑增加 volatile 关键字来提供可见性保障。  

# 09 wait 和 notify为什么要在synchronized 代码块中
> **实现 wait/notify 机制的条件**：
调用 wait 线程和 notify 线程必须拥有相同对象锁。
wait() 方法和 notify()/notifyAll() 方法必须在 Synchronized 方法或代码块中。
1. wait 和 notify 用来实现多线程之间的协调，wait 表示让线程进入到阻塞状态，notify 表示让阻塞的线程唤醒。
2. 二者必须成对出现，从而实现多线程之间的通信。
3.  Synchronized 可以实现一个等待一个唤醒这样的互斥条件
4. 为了避免 wait/notify 的错误使用，jdk 强制要求把 wait/notify 写在同步代码块里面，否则会抛出 IllegalMonitorStateException
5. wait/notify 的特性，非常适合实现生产者消费者的模型

# 10 ThreadLocal的实现原理
1. ThreadLocal 是一种线程隔离机制，提供多线程环境下对于共享变量的安全访问。
2. ThreadLocal 用了一种空间换时间的设计思想，也就是说在每个线程里面，都有一个容器来存储共享变量的副本，然后每个线程只对自己的变量副本来做更新操作，这样既解决了线程安全问题，又避免了多线程竞争加锁的开销。
3. ThreadLocal 原理是，在 Thread 类里面有一个成员变量ThreadLocalMap，它专门来存储当前线程的共享变量副本，后续这个线程对于共享变量的操作，都是从这个 ThreadLocalMap 里面进行变更，不会影响全局共享变量的值。
> 在 ThreadLocal 中，除了空间换时间的设计思想以外，还有一些比较好的设计思想，比如线性探索解决 hash 冲突，数据预清理机制、弱引用 key 设计尽可能避免内存泄漏等。

# 11 基于数组的阻塞队列 ArrayBlockingQueue 原理
1. 阻塞队列（BlockingQueue）是在队列的基础上增加了两个附加操作:
  - 1.1  在队列为空的时候，获取元素的线程会等待队列变为非空。
  - 1.2   当队列满时，存储元素的线程会等待队列可用。
2. 由于阻塞队列的特性，可以非常容易实现生产者消费者模型，也就是生产者只需要关心数据的生产，消费者只需要关注数据的消费，所以如果队列满了，生产者就等待，同样，队列空了，消费者也需要等待。 
3. 要实现这样的一个阻塞队列，需要用到两个关键的技术，队列元素的存储、以及线程阻塞和唤醒
4. 而 ArrayBlockingQueue 是基于数组结构的阻塞队列，也就是队列元素是存储在一个数组结构里面，并且由于数组有长度限制，为了达到循环生产和循环消费的目的，ArrayBlockingQueue 用到了循环数组。
5. 而线程的阻塞和唤醒，用到了 J.U.C 包里面的 ReentrantLock 和 Condition。Condition 相当于 wait/notify 在 JUC 包里面的实现。

# 12 怎么理解线程安全
1. 在多个线程访问某个方法或者对象的时候，不管通过任何的方式调用以及线程如何去交替执行。在程序中不做任何同步干预操作的情况下，这个方法或者对象的执行/修改都能按照预期的结果来反馈，那么这个类就是线程安全的。
2. 线程安全体现在三个方面：原子性、有序性、可见性。
 - a. 原子性：一个线程执行一系列程序指令操作的时候，它应该是不可中断的，就是一段程序只能由一个线程完整的执行完成，而不能存在多个线程干扰。 主要是由于CPU上线问切换引起的。Synchronized 关键字可解决原子性问题
 - b. 可见性：某个线程对共享变量的修改，对其他线程不是实时可见的。原因可能是：CPU 的高速缓存、CPU 的指令重排序、编译器的指令重排序。
 - c. 有序性：程序编写的指令顺序和最终 CPU 运行的指令顺序可能出现不一致的现象，即指令重排序。它也会导致可见性问题。Volatile 关键字来解决。
3. 导致有序性、原子性、可见性问题的本质，是为了最大化提升CPU 利用率导致的。比如为了提升 CPU 利用率，设计了三级缓存、设计了 StoreBuffer、设计了缓存行这种预读机制、在操作系统里面，设计了线程模型、在编译器里面，设计了编译器的深度优化机制。 

# 13 什么是可重入，什么是可重入锁? 它用来解决什么问题?
1. 一个线程如果抢占到了互斥锁资源，在锁释放之前再去竞争同一把锁的时候，不需要等待，只需要记录重入次数。
2. Synchronized、ReentrantLock 等可重入。读写锁StampedLock不可重入。
3. 锁的可重入性，主要解决的问题是**避免线程死锁的问题**。  因为一个已经获得同步锁 X 的线程，在释放锁 X 之前再去竞争锁 X 的时候，相当于会出现自己要等待自己释放锁，这很显然是无法成立的。

# 14 ReentrantLock 的实现原理
1. ReentrantLock 是一种可重入的排它锁，主要用来解决多线程对共享资源竞争的问题。
2. 特性：
	- 2.1  支持可重入 ： 获得锁的线程在释放锁之前再次去竞争同一把锁的时候，不需要加锁就可以直接访问
  - 2.2  支持公平和非公平特性
  - 2.3  提供了阻塞竞争锁和非阻塞竞争锁的两种方法，分别是 lock()和 tryLock()。
3. 底层实现：
  - 3.1  锁的竞争： 通过互斥变量，使用 CAS 机制来实现的
  - 3.2  没有竞争到锁的线程，使用了 AbstractQueuedSynchronizer 存储，底层是通过双向链表来实现的。当锁被释放之后，会从 AQS 队列里面的头部唤醒下一个等待锁的线程。
  - 3.3 公平和非公平的特性，主要是体现在竞争锁的时候，是否需要判断 AQS 队列存在等待中的线程
  - 3.4 锁的重入特性，在 AQS 里面有一个成员变量来保存当前获得锁的线程，当同一个线程下次再来竞争锁的时候，就不会去走锁竞争的逻辑，而是直接增加重入次数.
  
# 15 简述对线程池的理解
    线程池本质上是一种池化技术，是一种资源复用的思想。比如常见的连接池、内存池、对象池。
- 线程池复用的是线程资源，它的核心实际目标有两个：
1. 减少线程的频繁创建和销毁带来的性能开销：线程创建会涉及到 CPU 上下文切换、内存分配等工作；
2. 线程池本身会有参数来控制线程创建的数量，这样就可以避免无休止的创建线程带来的资源利用率过高的问题
- 线程池中的线程的生命周期是由任务运行的状态决定的，无法人为控制：
- 为了实现线程的复用，线程池里面用到了阻塞队列，简单来说就是线程池里面的工作线程处于一直运行状态，它会从阻塞队列中去获取待执行的任务，一旦队列空了，那这个工作线程就会被阻塞，直到下次有新的任务进来。
  
# 16 为什么引入偏向锁、轻量级锁，升级流程是什么
1. Synchronized 在 jdk1.6 版本之前，是通过重量级锁的方式来实现线程之间锁的竞争。底层底层依赖操作系统的 Mutex Lock 来实现互斥功能。
2. 在 jdk1.6 版本中，synchronized 增加了锁升级的机制，来平衡数据安全性和性能：
  - 2.1 线程去访问 synchronized 同步代码块的时候，synchronized 根据线程竞争情况，会先尝试在不加重量级锁的情况下去保证线程安全性。所以引入了偏向锁和轻量级锁的机制。
  - 2.2 偏向锁，就是直接把当前锁偏向于某个线程，简单来说就是通过 CAS 修改偏向锁标记，这种锁适合同一个线程多次去申请同一个锁资源并且没有其他线程竞争的场景。
  - 2.3 轻量级锁也可以称为自旋锁，基于自适应自旋的机制，通过多次自旋重试去竞争锁。自旋锁优点在于它避免避免了用户态到内核态的切换带来的性能开销。
3. 锁升级流程：
  - 3.1 synchronized 会尝试使用偏向锁的方式去竞争锁资源，如果能够竞争到偏向锁，表示加锁成功直接返回。如果竞争锁失败，说明当前锁已经偏向了其他线程。
  - 3.2 将锁升级到轻量级锁，在轻量级锁状态下，竞争锁的线程根据自适应自旋次数去尝试抢占锁资源，如果在轻量级锁状态下还是没有竞争到锁，
  - 3.3 升级到重量级锁，在重量级锁状态下，没有竞争到锁的线程就会被阻塞，线程状态是 Blocked。
  - 3.4 处于锁等待状态的线程需要等待获得锁的线程来触发唤醒。
4. 总的来说， Synchronized 的锁升级的设计思想，在我看来本质上是一种性能和安全性的平衡，也就是如何在不加锁的情况下能够保证线程安全性。  比如 Mysql 里面的 MVCC 使用版本链的方式来解决多个并行事务的竞争问题。

# 17 ReentrantLock 是如何实现锁公平和非公平性的
1. 公平： 竞争锁资源的线程，严格按照请求顺序来分配锁。
2. 非公平：竞争锁资源的线程，允许插队来抢占锁资源。（默认）
3. ReentrantLock 内部使用了 AQS 来实现锁资源的竞争，没有竞争到锁资源的线程，会加入到 AQS 的同步队列里面
	- 3.1 公平锁：有等待线程则加入队尾
  - 3.2 非公平锁：先尝试抢占资源，抢不到再加入。
4. 默认非公平，应该是考虑到 AQS 再把等待队列里面的线程唤醒，这里会涉及到内核态的切换， 如果是非公平策略，当前线程正好在上一个线程释放锁的临界点抢占到了锁，就意味着这个线程不需要切换到内核态，虽然对原本应该要被唤醒的线程不公平，但是提升了锁竞争的性能。
  
# 18 线程状态BLOCKED 和 WAITING 的区别  
1. 都属于下城的阻塞等待状态
2. BLOCKED 状态是指线程在等待监视器锁的时候的阻塞状态。也就是在多个线程去竞争 Synchronized 同步锁的时候，没有竞争到锁资源的线程，会被阻塞等待，这个时候线程状态就是 BLOCKED。
3. WAITING 状态，表示线程的等待状态，在这种状态下，线程需要等待某个线程的特定操作才会被唤醒。我们可以使用 Object.wait()、Object.join()、LockSupport.park()这些方法使得线程进入到 WAITING 状态，在这个状态下，必须要等待特定的方法来唤醒，比如 Object.notify 方法可以唤醒 Object.wait()方法阻塞的线程LockSupport.unpark()可以唤醒 LockSupport.park()方法阻塞的线程
4. 二者的区别；
 - 4.1 BLOCKED 是锁竞争失败后被被动触发的状态，WAITING 是人为的主动触发的状态
 - 4.2 BLCKED 的唤醒时自动触发的，而 WAITING 状态是必须要通过特定的方法来主动唤醒
 
# 19 wait 和 sleep 是否会触发锁的释放以及 CPU 资源的释放
1. Object.wait()方法，会释放锁资源以及 CPU 资源
2. Thread.sleep()方法，不会释放锁资源，但是会释放CPU资源。
3. wait()方法是让一个线程进入到阻塞状态，而这个方法必须要写在一个Synchronized 同步代码块里面。因为 wait/notify 是基于共享内存来实现线程通信的工具，这个通信涉及到条件的竞争，所以在调用这两个方法之前必须要竞争锁资源。当线程调用 wait 方法的时候，表示当前线程的工作处理完了，意味着让其他竞争同一个共享资源的线程有机会去执行。但前提是其他线程需要竞争到锁资源，所以 wait 方法必须要释放锁，否则就会导致死锁的问题。
4. Thread.sleep()方法，只是让一个线程单纯进入睡眠状态，这个方法并没有强制要求加 synchronized 同步锁。而且从它的功能和语义来说，也没有这个必要。当然，如果是在一个 Synchronized 同步代码块里面调用这个Thread.sleep，也并不会触发锁的释放
5. 凡是让线程进入阻塞状态的方法，操作系统都会重新调度实现 CPU 时间片切换，这样设计的目的是提升 CPU 的利用率。

# 20 DCL 单例模式设计为什么需要 volatile 修饰实例对象
1. 存在不完整对象的问题。而这个不完整对象的本质，是因为指令重排序导致的
2. instance=new Instance()构建一个实例对象的时候，因为 new 这个操作并不是原子的。
3. 这句代码最终会被编译成 3 条指令：
 - 3.1 为对象分配内存空间
 - 3.2 初始化对象
 - 3.3 把实例对象赋值给 instance 引用
4. 可能会导致其他线程可能拿到一个不完整的对象，也即 instance已经分配了引用实例，但是这个实例的初始化指令还没执行。 
5. 所以增加一个 volatile 关键字修饰，volatile 底层使用了内存屏障机制来避免指令重排序
 
 # 21 线程池的线程回收
 1. 线程池里面分为核心线程和非核心线程。线程池里面分为核心线程和非核心线程。
  - 1.1 向线程池里面添加任务的时候，被动初始化
  - 1.2 主动调用 prestartAllCoreThreads 方法
 2. 当线程池里面的队列满了的情况下，为了增加线程池的任务处理能力。 线程池会增加非核心线程。
  - 核心线程和非核心线程的数量，是在构造线程池的时候设置的，也可以动态进行更改。
 3.  由于非核心线程是为了解决任务过多的时候临时增加的，所以当任务处理完成后，工作线程处于空闲状态的时候，就需要回收。
 4. 所有工作线程都是从阻塞队列中去获取要执行的任务，所以只要在一定时间内，阻塞队列没有任何可以处理的任务，那这个线程就可以结束了。这个功能是通过阻塞队列里面的 poll 方法来完成的。这个方法提供了超时时间和超时时间单位这两个参数当超过指定时间没有获取到任务的时候，poll 方法返回 null，从而终止当前线程完成线程回收。
 5. 默认情况下，线程池只会回收非核心线程，如果希望核心线程也要回收，可以设置 allowCoreThreadTimeOut 这个属性为 true，一般情况下我们不会去回收核心线程。因为线程池本身就是实现线程的复用，而且这些核心线程在没有任务要处理的时候是处于阻塞状态
 
 # 22 Java 官方提供了哪几种线程池，分别有什么特点
 > Executors
 1. newCachedThreadPool: 一种可以缓存的线程池，它可以用来处理大量短期的突发流量。
   > 最大线程数是 Integer.MaxValue，线程存活时间是 60 秒，阻塞队列用的是 SynchronousQueue，这是一种不存才任何元素的阻塞队列，也就是每提交一个任务给到线程池，都会分配一个工作线程来处理，由于最大线程数没有限制。所以它可以处理大量的任务，另外每个工作线程又可以存活 60s，使得这些工作线程可以缓存起来应对更多任务的处理。
2. newFixedThreadPool: 一种固定线程数量的线程池。   
 > 核心线程和最大线程数量都是一个固定的值,如果任务比较多工作线程处理不过来，就会加入到阻塞队列里面等待。,
3. newSingleThreadExecutor:  只有一个工作线程的线程池。
 > 线程数量无法动态更改，因此可以保证所有的任务都按照 FIFO 的方式顺序执行。
4. newScheduledThreadPool: 具有延迟执行功能的线程池,  可以用它来实现定时调度
5. newWorkStealingPool: Java8 里面新加入的一个线程池它内部会构建一个 ForkJoinPool，利用工作窃取的算法并行处理请求。

6. 这些线程都是通过工具类 Executors 来构建的，线程池的最终实现类是 ThreadPoolExecutor。

# 23 对 Happens-Before 的理解
1. Happens-Before 是一种**可见性模型**，也就是说，在多线程环境下，原本因为指令重排序的存在会导致数据的可见性问题，也就是 A 线程修改某个共享变量对 B 线程不可见。因此，JMM 通过 Happens-Before 关系向开发人员提供跨越线程的内存可见性保证。如果一个操作的执行结果对另外一个操作可见，那么这两个操作之间必然存在Happens-Before 管理。
2. ，Happens-Before 关系只是描述结果的可见性，并不表示指令执行的先后顺序，也就是说只要不对结果产生影响，仍然允许指令的重排序。
3. 在 JMM 中存在很多的 Happens-Before 规则。
 - 3.1 程序顺序规则：不管怎么重排序，单线程的程序的执行结果不能改变
 - 3.2 传递性规则
 - 3.3 volatile 变量规则，对一个 volatile 修饰的变量的写一定 happens-before 于任意后续对这个 volatile 变量的读操作
 - 3.4 监视器锁规则： 一个线程对于一个锁的释放锁操作，一定 happens-before 与后续线程对这个锁的加锁操作
 - 3.5 线程启动规则： start()方法最先执行
 - 3.6 join 规则：
 
# 24 线程池是如何实现线程复用的
1. 采用了生产者消费者的模式，来实现线程复用。
2. 略

# 25 阻塞队列被异步消费怎么保持顺序
1. 阻塞队列本身是符合 FIFO 特性的队列，也就是存储进去的元素符合先进先出的规则。
2. 在阻塞队列里面，使用了 condition 条件等待来维护了两个等待队列，
  - 2.1 一个是队列为空的时候存储被阻塞的消费者
  - 2.2 另一个是队列满了的时候存储被阻塞的生产者
  - 2.3 并且存储在等待队列里面的线程，都符合 FIFO 的特性
3. 对于阻塞队列的消费过程，有两种情况。
 - 3.1 当阻塞队列里面已经包含了很多任务，这个时候启动多个消费者去消费的时候，它的有序性保证是通过加锁来实现的，也就是每个消费者线程去阻塞队列获取任务的时候必须要先获得排他锁。
 - 3.2  如果有多个消费者线程因为阻塞队列中没有任务而阻塞，这个时候这些线程是按照 FIFO 的顺序存储到condition 条件等待队列中的。 当阻塞队列中开始有任务要处理的时候，这些被阻塞的消费者线程会严格按照 FIFO 的顺序来唤醒，从而保证了消费的顺序型。以上就是我对这个问题的理解。
 
# 26 任务数超过线程池的核心线程数时，如何不进入队列，而直接启用最大线程数
    当我们提交一个任务到线程池的时候，它的工作原理分为四步。
1. 预热核心线程
2. 把任务添加到阻塞队列
3. 如果添加到阻塞队列失败，则创建非核心线程增加处理效率
4. 如果非核心线程数达到了阈值，就触发拒绝策
  
  所以，如果希望这个任务不进入队列，那么只需要去影响第二步的执行逻辑就行了。Java 中线程池提供的构造方法里面，有一个参数可以修改阻塞队列的类型。其中，就有一个阻塞队列叫 SynchronousQueue， 这个队列不能存储任何元素。它的特性是，每生产一个任务，就必须要指派一个消费者来处理，否则就会阻塞生产者。
  基于这个特性，只要把线程池的阻塞队列替换成 SynchronousQueue。就能够避免任务进入到阻塞队列，而是直接启动最大线程数去处理这个任务。以上就是我对这个问题的理解。

# 27 SimpleDateFormat 是否线程安全
1. 不是线程安全的
2. SimpleDateFormat 类内部有一个 Calendar 对象引用,用来储存和这个 SimpleDateFormat 相关的日期信息。当我们把 SimpleDateFormat 作为多个线程的共享资源来使用的时候。意味着多个线程会共享 SimpleDateFormat 里面的 Calendar 引用，多个线程对于同一个 Calendar 的操作，会出现数据脏读现象导致一些不可预料的错误。
3. 在实际应用中，我认为有 4 种方法可以解决这个问题。
 - 3.1 把 SimpleDateFormat 定义成局部变量，每个线程调用的时候都创建一个新的实例。
 - 3.2 使用 ThreadLocal 工具，把 SimpleDateFormat 变成线程私有的
 - 3.3 加同步锁，在同一时刻只允许一个线程操作 SimpleDateFormat
 - 3.4 在 Java8 里面引入了一些线程安全的日期 API，比如 LocalDateTimer、DateTimeFormatter 等

# 28 ThreadLocal 是否会内存泄漏
1. 不恰当的使用 ThreadLocal，会造成内存泄漏问题。
2.  线程的私有变量 ThreadLocalMap 里面的 key 是一个弱引用。弱引用的特性，就是不管是否存在直接引用关系， 当成员 ThreadLocal 没用其他的强引用关系的时候，这个对象会被 GC 回收掉。从而导致 key 可能变成 null，造成这块内存永远无法访问，出现内存泄漏的问题。规避内存泄漏的方法有两个：
 - 2.1 通过扩大成员变量 ThreadLoca 的作用域，避免被 GC 回收
 - 2.2 每次使用完 ThreadLocal 以后，调用 remove 方法移除对应的数据
第一种方法虽然不会造成key为null的现象，但是如果后续线程不再继续访问这个key。也会导致这个内存一直占用不释放，最后造成内存溢出的问题。 最好是在使用完以后调用 remove 方法移除。

> java中的四种引用：
1. 默认强引用，对象回收会调用 finalize() 方法
		只要强引用存在，垃圾收集器将永远不会回收被引用的对象，哪怕内存不足时，JVM也会直接抛出OutOfMemoryError，不会去回收。如果想中断强引用与对象之间的联系，可以显示的将强引用赋值为null，这样一来，JVM就可以适时的回收对象了。
2. 软引用(SoftReference )：用来描述一些非必需但仍有用的对象。在内存足够的时候，软引用对象不会被回收，只有在内存不足时，系统则会回收软引用对象，如果回收了软引用对象之后仍然没有足够的内存，才会抛出OutOfMemoryError。这种特性常常被用来实现缓存技术，比如网页缓存，图片缓存等
3. 弱引用(WeakReference ):弱引用的引用强度比软引用要更弱一些，无论内存是否足够，只要 JVM 开始进行垃圾回收，那些被弱引用关联的对象都会被回收。
4. 虚引用(PhantomReference ):虚引用是最弱的一种引用关系，如果一个对象仅持有虚引用，那么它就和没有任何引用一样，它随时可能会被回收。 永远无法通过虚引用来获取对象。虚引用必须要和 ReferenceQueue 引用队列一起使用。当垃圾回收器准备回收一个对象时，如果发现它还有引用，那么就会在回收对象之前，把这个引用加入到与之关联的引用队列中去。主要用于清理堆外内存。

# 29 ConcurrentHashMap 是如何保证线程安全的
1. JDK1.7: 使用的数组 加 链表的结构，其中数组分为两类，大数组 Segment 和 小数组 HashEntry，而加锁是通过给 Segment 添加ReentrantLock 重入锁来保证线程安全的。
  -  底层实现是数组加链表的形式，所以在数据比较多情况下，因为要遍历整个链表，会降低访问性能。
2. JDK1.8:    数组 加 链表 加 红黑树的方式实现，它是通过 CAS 或者 synchronized 来保证线程安全的，并且缩小了锁的粒度，查询性能也更高。
 - 当链表长度大于 8，并且数组长度大于 64 时，链表就会升级为红黑树
 - putVal使用 CAS加 volatile 和 synchronized ：
 -   添加元素时首先会判断容器是否为空
 -   如果为空则使用volatile加CAS来初始化；如果容器不为空，则根据存储的元素计算该位置是否为空
 -   如果根据存储的元素计算结果为空则利用CAS设置该节点；
 -   如果根据存储的元素计算为空不为空，则使用 synchronized，然后，遍历桶中的数据，并替换或新增节点到桶中
 -   最后再判断是否需要转为红黑树。这样就能保证并发访问时的线程安全了。
 - 1.8 通过对头结点加锁来保证线程安全的。
 
 # 30 synchronized 和 Lock 的区别
 |   项   |  synchronized    |    Lock  |
| ---- | ---- | ---- |
|  特性    |JAVA关键字，在JVM层面      |J.U.C包中的接口      |
|  获取    |A获得锁，B等待，A阻塞，B一直等待      |可尝试获得锁，线程可以不用一直等待      |
|  释放   | 执行完同步代码或发生异常，被动释放     |在finally中国释放，避免死锁      |
|  状态    |无法判断      | 可以判断      |
|  类型    | 可重入，不可中断，非共偶     | 可重入，可中断，可公平，可非公平      |
|  性能    |   少量同步   | 大量同步     |

 