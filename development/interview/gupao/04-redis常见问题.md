---
title: 04-redis常见问题
description: redis常见问题收集
published: true
date: 2023-09-12T09:59:23.378Z
tags: redis, 咕泡, 面试
editor: markdown
dateCreated: 2023-09-08T09:40:11.104Z
---

# 04-redis常见问题
 
 ## 01 对redis的理解
 1. Redis 是一个高性能的基于 Key-Value 结构存储的 Nosql 开源数据库。
 2. 一般采用 Redis 来实现分布式缓存，从而提高数据的检索效率。
 3. Redis 之所以这么流行，主要有几个特点：
   - 基于内存存储，在进行数据 IO 操作时，能够 10WQPS
   - 提供了非常丰富的数据存储结构，如 String、List、Hash、Set、ZSet 等。
   -  底层采用单线程实现数据的 IO，所以在数据算法层面并不需要要考虑并发安全性，所以底层算法上的时间复杂度基本上都是常量
4. Redis 虽然是内存存储，但是它也可以支持持久化，避免因为服务器故障导致数据丢失的问题

`基于这些特点，Redis 一般用来实现分布式缓存，从而降低应用程序对关系型数据库检索带来的性能影响。除此之外，Redis 还可以实现分布式锁、分布式队列、排行榜、查找附近的人等功能，为复杂应用提供非常方便和成熟的解决方案`

## 02 Redis 为什么这么快
1. 决定 Redis 请求效率的因素主要是三个方面，分别是网络、cpu、内存。
2. 在网络层面，Redis 采用**多路复用**的设计，提升了并发处理的连接数，不过这个阶段，Server 端的所有 IO 操作，都是由同一个主线程处理的这个时候 IO 的瓶颈就会影响到 Redis 端的整体处理性能。所以从 Redis6.0 开始，在多路复用及层面增加了多线程的处理，来优化 IO 处理的能力。不过，具体的数据操作仍然是由主线程来处理的，所以我们可以认为 Redis 对于数据 IO的处理依然是单线程。
3. 从 CPU 层面来说，Redis 只需要采用单线程即可，原因有两个。
 - 3.1 如果采用多线程，对于 Redis 中的数据操作，都需要通过同步的方式来保证线程安全性，这反而会影响到 redis 的性能
 - 3.2 在 Linux 系统上 Redis 通过 pipelining 可以处理 100w 个请求每秒，而应用程序的计算复杂度主要是 O(N) 或 O(log(N)) ，不会消耗太多 CPU；
4.  从内存层面来说，Redis 本身就是一个内存数据库，内存的 IO 速度本身就很快，所以内存的瓶颈只是受限于内存大小
5. 最后， Redis 本身的数据结构也做了很多的优化，比如压缩表、跳跃表等方式降低了时间复杂读，同时还提供了不同时间复杂度的数据类型。使得开发人员能够有更多合适的选择。

## 03 Redis 和 Mysql 如何保证数据一致性
1. 一般先更新数据库，再更新缓存，或者 先删除缓存，再更新数据库，但是都可能存在不一致性
2. 在极端情况下仍然保证 Redis 和 Mysql 的数据一致性，就只能采用最终一致性方案。
  - 2.1 比如基于 RocketMQ 的可靠性消息通信，来实现最终一致性。（更新失败的请求写入mq，同步到redis）
  - 2.2 直接通过 Canal 组件，监控 Mysql 中 binlog 的日志，把更新后的数据同步到 Redis 里面。
3. 通过读写锁的方式来保证强一致性  ：在数据更新的时候，其他任何请求都无法访问缓存中的数据，直到数据更新完毕，从而保证了数据的强一致性

## 04 Redis 存在线程安全问题吗
1. Redis Server 本身是一个线程安全的 K-V 数据库，也就是说在 Redis Server 上执行的指令，不需要任何同步机制，不会存在线程安全问题。
2. Redis 6.0 里面，增加了多线程的模型，但是增加的多线程只是用来处理网络 IO 事件，对于指令的执行过程，仍然是由主线程来处理，所以不会存在多个线程通知执行操作指令的情况。
` Redis 没有采用多线程来执行指令，有几个方面的原因:`
  - 2.1 Redis Server 本身可能出现的性能瓶颈点无非就是网络 IO、CPU、内存。但是 CPU不是 Redis 的瓶颈点，所以没必要使用多线程来执行指令。
  - 如果采用多线程，意味着对于 redis 的所有指令操作，都必须要考虑到线程安全问题，也就是说需要加锁来解决，这种方式带来的性能影响反而更大。
3. 从 Redis 客户端层面:虽然 Redis Server 中的指令执行是原子的，但是如果有多个 Redis 客户端同时执行多个指令的时候，就无法保证原子性。
`对于客户端层面的线程安全性问题，解决方法有很多，比如尽可能的使用 Redis里面的原子指令(SETNX/GETSET/INCR/DECR/MSET/MSETNX/HSET/MSETNX/LPUSH/RPUSH)，或者对多个客户端的资源访问加锁，或者通过 Lua 脚本来实现多个指令的操作等等。` 

## 05 RDB 和 AOF 的实现原理以及优缺点
1. 两种持久化机制的特性：RDB 是通过快照方式实现持久化、AOF 是通过命令追加的方式实现持久化。
2. 两种机制的工作原理：
  - 2.1 RDB 持久化机制会根据快照触发条件，把内存里面的数据快照写入到磁盘，以二进制的压缩文件进行存储。
     - RDB 快照的触发方式:
     - 执行 bgsave 命令触发异步快照，执行 save 命令触发同步快照，同步快照会阻塞客户端的执行指令。
     - 根据 redis.conf 文件里面的配置，自动触发 bgsave
     - 主从复制的时候触发
  - 2.2  AOF 持久化机制是近乎实时的方式来完成持久化的，就是客户端执行一个数据变更的操作，Redis Server 就会把这个命令追加到 aof 缓冲区的末尾，然后再把缓冲区的数据写入到磁盘的 AOF 文件里面，至于最终什么时候真正持久化到磁盘，是根据刷盘的策略来决定的。
    - 为了避免追加的方式导致 AOF 文件过大的问题，Redis 提供了 AOF 重写机制,当 AOF 文件的大小达到某个阈值的时候，就会把这个文件里面相同的指令进
行压缩。
3. AOF 和 RDB 的优缺点:
  - 3.1 RDB 是每隔一段时间触发持久化，因此数据安全性低，AOF 可以做到实时持久化，数据安全性较高
  - 3.2 RDB 文件默认采用压缩的方式持久化，AOF 存储的是执行指令，所以 RDB 在数据恢复的时候性能比 AOF 要好
4. (RDB和AOF到底该如何选择)[https://juejin.cn/post/6926039904590037005]:
  - 4.1 

## 06 Redis 的内存淘汰算法和原理
1. Redis 里面的内存淘汰策略，是指内存的使用率达到 maxmemory 上限的时候的一种内存释放的行为。
2. 提供了很多中内存淘汰算法，归纳起来主要就四种：
  - 2.1  Random 算法，随机移除某个 key
  - 2.2  TTL 算法 ，在设置了过期时间的键中，把更早过期时间的 key 有限移除
  - 2.3  LRU 算法，移除最近很少使用的 key
  - 2.4  LFU 算法，移除最近很少使用的 key。 多了访问频率维度的统计

## 07 分布式锁的理解和实现
1. 分布式锁，是一种跨进程的跨机器节点的互斥锁，它可以用来保证多机器节点对于共享资源访问的排他性。
2. 分布式锁和线程锁本质上是一样的，都需要满足锁的几个重要特性：
  - 2.1 排他性，也就是说，同一时刻只能有一个节点去访问共享资源。
  - 2.2 可重入性，允许一个已经获得锁的进程，在没有释放锁之前再次重新获得锁。
  - 2.3 锁的获取、释放的方法
  - 2.4 锁的失效机制，避免死锁的问题
  > 只要能够满足这些特性的技术组件都能够实现分布式锁。
3. Redis，它里面提供了 SETNX 命令可以实现锁的排他性，当 key 不存在就返回 1，存在就返回 0。然后还可以用 expire 命令设置锁的失效时间，从而避免死锁问题。当然有可能存在锁过期了，但是业务逻辑还没执行完的情况。 所以这种情况，可以写一个定时任务对指定的 key 进行续期.
4. Redisson 这个开源组件，就提供了分布式锁的封装实现，并且也内置了一个 WatchDog 机制来对 key 做续期。
5. 如果在 Redis搭建了高可用集群的情况下出现主从切换导致 key 失效，这个问题也有可能造成多个线程抢占到同一个锁资源的情况，所以 Redis 官方也提供了一个 RedLock 的解决办法，但是实现会相对复杂一些。
6. 分布式锁应该是一个 CP 模型，而 Redis 是一个 AP 模型，所以在集群架构下由于数据的一致性问题导致极端情况下出现多个线程抢占到锁的情况很难避免。
7. 那么基于 CP 模型又能实现分布式锁特性的组件，我认为可以选择 Zookeeper 或者etcd，在数据一致性方面，zookeeper 用到了 zab 协议来保证数据的一致性，etcd用到了 raft 算法来保证数据一致性。在锁的互斥方面，zookeeper 可以基于有序节点再结合 Watch 机制实现互斥和唤醒，etcd 可以基于 Prefix 机制和 Watch 实现互斥和唤醒。


## 08 缓存雪崩和缓存穿透的理解，以及如何避免
1. **缓存雪崩**： 缓存里面的大量数据，在**同一个时刻全部过期**，原本缓存组件抗住的大部分流量全部**请求到了数据库**。导致数据库压力增加造成数据库服务器崩溃的现象。
 - 雪崩的原因：
 - 1.1 缓存中间件宕机，当然可以对缓存中间件做高可用集群来避免
 - 1.2 缓存中大部分 key 都设置了相同的过期时间，导致同一时刻这些 key 都过期了。对于这样的情况，可以在失效时间上增加一个 1 到 5 分钟的随机值。
2. **缓存穿透** ：短时间内有**大量的不存在的 key 请求到应用里面**，而这些不存在的 key 在缓存里面又找不到，从而全部穿透到了数据库，造成数据库压力。
  - 2.1 这个场景的核心问题是针对缓存的一种攻击行为，正常的业务里面，即便是出现了这样的情况，由于缓存的不断预热，影响不会很大。
  - 2.2 攻击行为就需要具备时间是的持续性，而只有 key 确实在数据库里面也不存在的情况下，才能达到这个目的，所以，我认为有两个方法可以解决：
    - 2.2.1 把无效的 key 也保存到 Redis 里面，并且设置一个特殊的值，比如“null”，这样的话下次再来访问，就不会去查数据库了
    - 2.2.2 布隆过滤器来实现，在系统启动的时候把目标数据全部缓存到布隆过滤器里面，当攻击者用不存在的 key 来请求的时候，先到布隆过滤器里面查询，如果不存在，那意味着这个 key 在数据库里面也不存在。（它采用了 bitmap 来进行数据存储，占用的内存空间很少。）
3. 不用放大雪崩和穿透的影响，因为：
  - 3.1 在一个成熟的系统里面，对于比较重要的热点数据，必然会有一个专门缓存系统来维护，同时它的过期时间的维护必然和其他业务的 key 会有一定的差别。而且非常重要的场景，我们还会设计多级缓存系统。
  - 3.2 即便是触发了缓存雪崩，数据库本身的容灾能力也并没有那么脆弱，数据库的主从、双主、读写分离这些策略都能够很好的缓解并发流量。
  - 3.3 ，数据库本身也有最大连接数的限制，超过限制的请求会被拒绝，再结合熔断机制，也能够很好的保护数据库系统，最多就是造成部分用户体验不好。
  - 3.4 另外，在程序设计上，为了避免缓存未命中导致大量请求穿透到数据库的问题，还可以在访问数据库这个环节加锁。虽然影响了性能，但是对系统是安全的。
  