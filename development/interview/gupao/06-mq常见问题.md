---
title: 06-mq常见问题
description: 分布式消息队列常见问题
published: true
date: 2023-09-21T07:07:39.650Z
tags: mq, 咕泡, 面试
editor: markdown
dateCreated: 2023-09-19T07:10:16.560Z
---

# 06-mq常见问题

## 01 什么是消息队列
1.消息队列 Message Queue，简称 MQ。是一种应用间的通信方式，主要由三个部分组成：
  - 1.1 **生产者：Producer**：消息的产生者与调用端主要负责消息所承载的业务信息的实例化是一个队列的发起方
  - 1.2 **代理：Broker**： 主要的处理单元，负责消息的存储、投递、及各种队列附加功能的实现，是消息队列最核心的组成部分
  - 1.3 **消费者：Consumer**：一个消息队列的终端也是消息的调用端具体是根据消息承载的信息，处理各种业务逻辑。
2. 消息队列的**应用场景**较多，常用的可以分为三种： 
  - 2.1 **异步处理**： 主要应用于对实时性要求不严格的场景，比如用户注册发送验证码、下单通知、发送优惠券等等
  - 2.2 **应用解耦** ：把相关但耦合度不高的系统联系起来。 有关联但不哪么紧密的系统，，每个系统之间只需要把约定的消息发送到 MQ，另外的系统去消费即可。解决了各个系统可以采用不同的架构、语言来实现，从而大大增加了**系统的灵活性**。
  - 2.3 **流量削峰** ： 在大流量入口且短时间内业务需求处理不完的服务中心，为了权衡高可用，把大量的并行任务发送到 MQ 中，依据 MQ 的存储及分发功能，平稳的处理后续的业务，起到一个大流量缓冲的作用。
3. 常见的消息队列中间件主要有： ActiveMQ、RabbitMQ、Kafka、RocketMQ 这几种，  
 >  在架构技术选型的时候一般根据业务的需求选择合适的中间件：比如中小型公司，低吞吐量的一般用 ActiveMQ、RabbitMQ 较为合适，大数据高吞吐量的大型公司一般选用 Kafka 和 RocketMQ。
  
## 02 kafka 的零拷贝原理
1. 应用把磁盘中的某个文件内容发送到远程服务器上：
  - 磁盘 - 内核 buffer - 用户 buffer - socket buffer -  网卡缓冲区 - 目标服务器
2. 零拷贝通过DMA（Direct Memory Access）技术把文件内容复制到内核空间中的ReadBuffer，接着把包含数据位置和长度信息的文件描述符加载到 Socket Buffer 中，DMA 引擎直接可以把数据从内核空间中传递给网卡设备。  
3. 所谓零拷贝，并不是完全没有数据赋值，只是相对于用户空间来说，不再需要进行数据拷贝。对于前面说的整个流程来说，零拷贝只是减少了不必要的拷贝次数而已。
4. 程序中如何实现零拷贝：
  - 4.1  Linux 中，零拷贝技术依赖于底层的 sendfile()方法实现
  - 4.2 Java 中，FileChannal.transferTo() 方法的底层实现就是 sendfile() 方法。
  - 4.3 还有一个 mmap 的文件映射机制，原理是：将磁盘文件映射到内存, 用户通过修改内存就能修改磁盘文件。使用这种方式可以获取很大的 I/O 提升，省去了用户空间到内核空间复制的开销
  
## 03 Kafka 如何保证消息不丢失
1. Producer 端，需要确保消息能够到达 Broker 并实现消息存储：
  - 1.1 Producer 默认是异步发送消息，这种情况下要确保消息发送成功，有两个方法
    - a. 把异步发送改成同步发送，这样 producer 就能实时知道消息发送的结果。
    - b. 添加异步回调函数来监听消息发送的结果，如果发送失败，可以在回调中重试。
  - 1.2 Producer 本身提供了一个重试参数 retries，如果因为网络问题或者 Broker 故障导致发送失败，Producer 会自动重试。  
2.  Broker 端，Broker 需要确保 Producer 发送过来的消息不会丢失，也就是只需要把消息持久化到磁盘就可以了.
   - 2.1 但是，Kafka 为了提升性能，采用了异步批量刷盘的实现机制，也就是说按照一定的消息量和时间间隔来刷盘，而最终刷新到磁盘的这个动作，是由操作系统来调度的，所以如果在刷盘之前系统崩溃，就会导致数据丢失。
   - 2.2 Kafka 并没有提供同步刷盘的实现，所以针对这个问题，需要通过 Partition的副本机制和 acks 机制来一起解决。
   - 2.3  Partition 副本机制，它是针对每个数据分区的高可用策略，每个partition 副本集包含唯一的一个 Leader 和多个 Follower，Leader 专门处理事务类的请求，Follower 负责同步 Leader 的数据”。在这样的一种机制的基础上，kafka 提供了一个 acks 的参数，Producer 可以设置 acks参数再结合 Broker 的副本机制来个共同保障数据的可靠性.
   - 2.4 acks 有几个值的选择:
     - a. acks=0， 表示 producer 不需要等 Broker 的响应，就认为消息发送成功，这种情况会存在消息丢失。
     - b. acks=1，表示 Broker 中的 Leader Partition 收到消息以后，不等待其他 FollowerPartition 同步完，就给 Producer 返回确认，这种情况下 Leader Partition 挂了，会存在数据丢失。
     - c. acks=-1，表示 Broker 中的 Leader Parititon 收到消息后，并且等待 ISR 列表中的 follower 同步完成，再给 Producer 返回确认，这个配置可以保证数据的可靠性
3.  最后，就是 Consumer 必须要能消费到这个消息，实际上，我认为，只要 producer和 broker 的消息可靠的到了保障，那么消费端是不太可能出现消息无法消费的问题，除非是 Consumer 没有消费完这个消息就直接提交了，但是即便是这个情况，也可以通过调整 offset 的值来重新消费。    
  
## 04 Kafka 怎么避免重复消费
1. Kafka Broker 上存储的消息，都有一个 Offset 标记。然后 kafka 的消费者是通过 offSet 标记来维护当前已经消费的数据，每消费一批数据，Kafka Broker 就会更新 OffSet 的值，避免重复消费。
2. 默认情况下，消息消费完以后，会自动提交 Offset 的值，避免重复消费。Kafka 消费端的自动提交逻辑有一个默认的 5 秒间隔，也就是说在 5 秒之后的下一次向Broker 拉取消息的时候提交。所以在 Consumer 消费的过程中，应用程序被强制 kill 掉或者宕机，可能会导致 Offset没提交，从而产生重复提交的问题。除此之外，还有另外一种情况也会出现重复消费。在 Kafka 里面有一个 Partition Balance 机制，就是把多个 Partition 均衡的分配给多个消费者。就会触发 Kafka 的 Rebalance 机制，从而导致 Offset 自动提交失败。
3. 基于这样的背景下，我认为解决重复消费消息问题的方法有几个：
  - 3.1 提高消费端的处理性能避免触发 Balance，比如可以用异步的方式来处理消息，缩短单个消息消费的市场。或者还可以调整消息处理的超时时间。还可以减少一次性从 Broker 上拉取数据的条数。
  - 3.2 可以针对消息生成 md5 然后保存到 mysql 或者 redis 里面，在处理消息之前先去mysql 或者 redis 里面判断是否已经消费过。这个方案其实就是利用幂等性的思想。
  
## 05  什么是 ISR，为什么需要引入 ISR
1. kafka 在 Partition 多副本设计的方案里面，有两个很关键的需求。**副本数据的同步**和**新 Leader 的选举**这两个需求都需要涉及到网络通信，Kafka 为了避免网络通信延迟带来的性能问题，以及尽可能的保证新选举出来的 Leader Partition 里面的数据是最新的，所以设计了ISR 这样一个方案。
2. ISR 全称是 in-sync replica，它是一个集合列表，里面保存的是和 Leader Parition 节点数据最接近的 Follower Partition
3. 如果某个 Follower Partition 里面的数据落后 Leader 太多，就会被剔除 ISR 列表。简单来说，ISR 列表里面的节点，同步的数据一定是最新的，所以后续的 Leader 选举，只需要从 ISR 列表里面筛选就行了。
4. 引入 ISR 这个方案的原因有两个：
  - 4.1 尽可能的保证数据同步的效率，因为同步效率不高的节点都会被踢出 ISR 列表。
  - 4.2 避免数据的丢失，因为 ISR 里面的节点数据是和 Leader 副本最接近的。
  
## 06 Kafka 如何保证消息消费的顺序性
1. 首先，在 kafka 的架构里面，用到了 Partition 分区机制来实现消息的物理存储，在同一个 topic 下面，可以维护多个 partition 来实现消息的分片。生产者在发送消息的时候，会根据消息的 key 进行取模，来决定把当前消息存储到哪个 partition 里面。消息是按照先后顺序有序存储到 partition 里面的。
2. 假设有一个 topic 存在三个 partition，而消息正好被路由到三个独立的 partition 里面。然后消费端有三个消费者通过 balance 机制分别指派了对应消费分区。因为消费者是完全独立的网络节点，所有可能会出现，消息的消费顺序不是按照发送顺序来实现的，从而导致乱序的问题。
3. 针对这个问题，一般的解决办法就是自定义消息分区路由的算法，然后把指定的 key都发送到同一个 Partition 里面。接着指定一个消费者专门来消费某个分区的数据，这样就能保证消息的顺序消费了。
2. 有些设计方案里面，在消费端会采用异步线程的方式来消费数据来提高消息的处理效率，那这种情况下，因为每个线程的消息处理效率是不同的，所以即便是采用单个分区的存储和消费也可能会出现无序问题，针对这个问题的解决办法就是在消费者这边使用一个阻塞队列，把获取到的消息先保存到阻塞队列里面，然后异步线程从阻塞队列里面去获取消息来消费。

  