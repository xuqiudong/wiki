---
title: 06-mq常见问题
description: 分布式消息队列常见问题
published: true
date: 2023-09-19T07:46:55.018Z
tags: mq, 咕泡, 面试
editor: markdown
dateCreated: 2023-09-19T07:10:16.560Z
---

# 06-mq常见问题

## 01 什么是消息队列
1.消息队列 Message Queue，简称 MQ。是一种应用间的通信方式，主要由三个部分组成：
  - 1.1 **生产者：Producer**：消息的产生者与调用端主要负责消息所承载的业务信息的实例化是一个队列的发起方
  - 1.2 **代理：Broker**： 主要的处理单元，负责消息的存储、投递、及各种队列附加功能的实现，是消息队列最核心的组成部分
  - 1.3 **消费者：Consumer**：一个消息队列的终端也是消息的调用端具体是根据消息承载的信息，处理各种业务逻辑。
2. 消息队列的**应用场景**较多，常用的可以分为三种： 
  - 2.1 **异步处理**： 主要应用于对实时性要求不严格的场景，比如用户注册发送验证码、下单通知、发送优惠券等等
  - 2.2 **应用解耦** ：把相关但耦合度不高的系统联系起来。 有关联但不哪么紧密的系统，，每个系统之间只需要把约定的消息发送到 MQ，另外的系统去消费即可。解决了各个系统可以采用不同的架构、语言来实现，从而大大增加了**系统的灵活性**。
  - 2.3 **流量削峰** ： 在大流量入口且短时间内业务需求处理不完的服务中心，为了权衡高可用，把大量的并行任务发送到 MQ 中，依据 MQ 的存储及分发功能，平稳的处理后续的业务，起到一个大流量缓冲的作用。
3. 常见的消息队列中间件主要有： ActiveMQ、RabbitMQ、Kafka、RocketMQ 这几种，  
 >  在架构技术选型的时候一般根据业务的需求选择合适的中间件：比如中小型公司，低吞吐量的一般用 ActiveMQ、RabbitMQ 较为合适，大数据高吞吐量的大型公司一般选用 Kafka 和 RocketMQ。
  
## 02 kafka 的零拷贝原理
1. 应用把磁盘中的某个文件内容发送到远程服务器上：
  - 磁盘 - 内核 buffer - 用户 buffer - socket buffer -  网卡缓冲区 - 目标服务器
2. 零拷贝通过DMA（Direct Memory Access）技术把文件内容复制到内核空间中的ReadBuffer，接着把包含数据位置和长度信息的文件描述符加载到 Socket Buffer 中，DMA 引擎直接可以把数据从内核空间中传递给网卡设备。  
3. 所谓零拷贝，并不是完全没有数据赋值，只是相对于用户空间来说，不再需要进行数据拷贝。对于前面说的整个流程来说，零拷贝只是减少了不必要的拷贝次数而已。
4. 程序中如何实现零拷贝：
  - 4.1  Linux 中，零拷贝技术依赖于底层的 sendfile()方法实现
  - 4.2 Java 中，FileChannal.transferTo() 方法的底层实现就是 sendfile() 方法。
  - 4.3 还有一个 mmap 的文件映射机制，原理是：将磁盘文件映射到内存, 用户通过修改内存就能修改磁盘文件。使用这种方式可以获取很大的 I/O 提升，省去了用户空间到内核空间复制的开销
  
## 03 Kafka 如何保证消息不丢失
1. Producer 端，需要确保消息能够到达 Broker 并实现消息存储：
  - 1.1 Producer 默认是异步发送消息，这种情况下要确保消息发送成功，有两个方法
    - a. 把异步发送改成同步发送，这样 producer 就能实时知道消息发送的结果。
    - b. 添加异步回调函数来监听消息发送的结果，如果发送失败，可以在回调中重试。
  - 1.2 Producer 本身提供了一个重试参数 retries，如果因为网络问题或者 Broker 故障导致发送失败，Producer 会自动重试。  
2.  Broker 端，Broker 需要确保 Producer 发送过来的消息不会丢失，也就是只需要把消息持久化到磁盘就可以了.
   - 2.1 但是，Kafka 为了提升性能，采用了异步批量刷盘的实现机制，也就是说按照一定的消息量和时间间隔来刷盘，而最终刷新到磁盘的这个动作，是由操作系统来调度的，所以如果在刷盘之前系统崩溃，就会导致数据丢失。
   - 2.2 Kafka 并没有提供同步刷盘的实现，所以针对这个问题，需要通过 Partition的副本机制和 acks 机制来一起解决。
   - 2.3  Partition 副本机制，它是针对每个数据分区的高可用策略，每个partition 副本集包含唯一的一个 Leader 和多个 Follower，Leader 专门处理事务类的请求，Follower 负责同步 Leader 的数据”。在这样的一种机制的基础上，kafka 提供了一个 acks 的参数，Producer 可以设置 acks参数再结合 Broker 的副本机制来个共同保障数据的可靠性.
   - 2.4 acks 有几个值的选择:
     - a. acks=0， 表示 producer 不需要等 Broker 的响应，就认为消息发送成功，这种情况会存在消息丢失。
     - b. acks=1，表示 Broker 中的 Leader Partition 收到消息以后，不等待其他 FollowerPartition 同步完，就给 Producer 返回确认，这种情况下 Leader Partition 挂了，会存在数据丢失。
     - c. acks=-1，表示 Broker 中的 Leader Parititon 收到消息后，并且等待 ISR 列表中的 follower 同步完成，再给 Producer 返回确认，这个配置可以保证数据的可靠性
3.  最后，就是 Consumer 必须要能消费到这个消息，实际上，我认为，只要 producer和 broker 的消息可靠的到了保障，那么消费端是不太可能出现消息无法消费的问题，除非是 Consumer 没有消费完这个消息就直接提交了，但是即便是这个情况，也可以通过调整 offset 的值来重新消费。    
  